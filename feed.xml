<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://gohugo.io/" version="0.121.2">Hugo</generator><title>DiagnoseAI Development Blog</title><link href="https://2023-comp0016-avanade-team4.github.io/diagnoseai-dev-blog/" rel="alternate" type="text/html" title="html"/><link href="https://2023-comp0016-avanade-team4.github.io/diagnoseai-dev-blog/feed.xml" rel="self" type="application/atom+xml" title="Atom"/><updated>2024-01-15T10:51:24+00:00</updated><id>https://2023-comp0016-avanade-team4.github.io/diagnoseai-dev-blog/</id><entry><title>Christmas Blog - Conversation history and validation chat</title><link href="https://2023-comp0016-avanade-team4.github.io/diagnoseai-dev-blog/posts/week-05/" rel="alternate" type="text/html" hreflang="en"/><id>https://2023-comp0016-avanade-team4.github.io/diagnoseai-dev-blog/posts/week-05/</id><published>2023-12-20T00:00:00+00:00</published><updated>2023-12-20T00:00:00+00:00</updated><content type="html">
&lt;p>This Christmas break (Starting from 21st December 2023 to 9th January 2024) the team had a much lighter workload during the holidays. However, time was still spent working on these core functionalities including development of a validation chat user interface, enabling conversation history for client chat, and , creation of an Image vectorization endpoint.&lt;/p>
&lt;div class="flex align-center gblog-post__anchorwrap">
&lt;h1 id="validation-chat-user-interface"
>
Validation Chat User Interface
&lt;/h1>
&lt;a data-clipboard-text="https://2023-comp0016-avanade-team4.github.io/diagnoseai-dev-blog/posts/week-05/#validation-chat-user-interface" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Validation Chat User Interface" href="#validation-chat-user-interface">
&lt;svg class="gblog-icon gblog_link">&lt;use xlink:href="#gblog_link">&lt;/use>&lt;/svg>
&lt;/a>
&lt;/div>
&lt;p>Having developed the document upload and vectorization features the focus was now on developing the validation chat user interface. The validation chat is a part of Uploader web app and is used to validate the language model&amp;rsquo;s understanding of the manuals uploaded.&lt;/p>
&lt;p>The interface consists of validation chat message interface and two display components rendering the extracted images and text from the document uploaded. Here&amp;rsquo;s a screenshot of the validation chat:&lt;/p>
&lt;p>&lt;p class="md__image">
&lt;img src="/diagnoseai-dev-blog/images/validation-chat.jpeg" alt="Image of the validation chat user interface" />
&lt;/p>
&lt;/p>
&lt;div class="flex align-center gblog-post__anchorwrap">
&lt;h1 id="conversation-history"
>
Conversation History
&lt;/h1>
&lt;a data-clipboard-text="https://2023-comp0016-avanade-team4.github.io/diagnoseai-dev-blog/posts/week-05/#conversation-history" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Conversation History" href="#conversation-history">
&lt;svg class="gblog-icon gblog_link">&lt;use xlink:href="#gblog_link">&lt;/use>&lt;/svg>
&lt;/a>
&lt;/div>
&lt;p>In an on field situation, there are multiple factors that a language model will need to keep in mind when suggesting solutions to the problems at hand. Consequently, it is important that the language model is capable of accessing the conversation history.&lt;/p>
&lt;p>After a discussion with the IXN project mentor to better understand the requirements, the team settled on using a conversation history window of ten messages as this was suited to the client requirements.&lt;/p>
&lt;p>Here&amp;rsquo;s a screenshot of the client chat accessing the conversation history.&lt;/p>
&lt;p>&lt;p class="md__image">
&lt;img src="/diagnoseai-dev-blog/images/client-conv-history.jpeg" alt="Image of the client chat accessing conversation history" />
&lt;/p>
&lt;/p>
&lt;div class="flex align-center gblog-post__anchorwrap">
&lt;h1 id="image-vectorization"
>
Image Vectorization
&lt;/h1>
&lt;a data-clipboard-text="https://2023-comp0016-avanade-team4.github.io/diagnoseai-dev-blog/posts/week-05/#image-vectorization" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Image Vectorization" href="#image-vectorization">
&lt;svg class="gblog-icon gblog_link">&lt;use xlink:href="#gblog_link">&lt;/use>&lt;/svg>
&lt;/a>
&lt;/div>
&lt;p>Another important aspect of the validation chat is the ability to vectorize the extracted images. Hence, a core API feature had to be developed to accept images and upload them into a specified vector index.&lt;/p>
&lt;p>To achieve this the image was sent to a GPT4-V vision model which generated a text summary of the image. The model was prompted to create a summary that could later be used for image based content retrieval. Here&amp;rsquo;s a screenshot of the standard request contents to the vision model.&lt;/p>
&lt;p>&lt;p class="md__image">
&lt;img src="/diagnoseai-dev-blog/images/vision-model-prompt.png" alt="Image of the request body being sent to the language model" />
&lt;/p>
&lt;/p>
&lt;p>Further, the text generated was vectorized and its embedding was uploaded to the Azure cognitive search index specified in the request body.&lt;/p></content></entry><entry><title>Week 2 - Gathering requirements</title><link href="https://2023-comp0016-avanade-team4.github.io/diagnoseai-dev-blog/posts/week-02/" rel="alternate" type="text/html" hreflang="en"/><id>https://2023-comp0016-avanade-team4.github.io/diagnoseai-dev-blog/posts/week-02/</id><published>2023-11-20T00:00:00+00:00</published><updated>2023-11-20T00:00:00+00:00</updated><content type="html">
&lt;p>This week (Monday was 20 November 2023) first week after the reading week, was primarily focused on gathering and formalizing client requirements and presenting a finalised requirements document to the client. Additionally, time was spent into breaking down the tasks required to develop the Core, Uploader and Web systems.&lt;/p>
&lt;div class="flex align-center gblog-post__anchorwrap">
&lt;h1 id="requirements-document"
>
Requirements document
&lt;/h1>
&lt;a data-clipboard-text="https://2023-comp0016-avanade-team4.github.io/diagnoseai-dev-blog/posts/week-02/#requirements-document" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Requirements document" href="#requirements-document">
&lt;svg class="gblog-icon gblog_link">&lt;use xlink:href="#gblog_link">&lt;/use>&lt;/svg>
&lt;/a>
&lt;/div>
&lt;p>Having estimated the time and effort it would require to implement the different features proposed to the client we came up with a formal requirement documents.&lt;/p>
&lt;p>Definitions were established for different features and stakeholders in the project. To avoid any ambiguity in the intepretation of the requirements document.&lt;/p>
&lt;p>Further, the requirements were broken down into functional, non-functional, system and user requirements. In addition, care was taken to distinguish the requirements that the system has to have and those that are optional using the keywords shall and should.&lt;/p>
&lt;p>The aforementioned requirements document can be found via &lt;a
class="gblog-markdown__link"
href="/diagnoseai-dev-blog/Requirements.pdf"
>this link&lt;/a>&lt;/p>
&lt;div class="flex align-center gblog-post__anchorwrap">
&lt;h1 id="task-breakdown"
>
Task breakdown
&lt;/h1>
&lt;a data-clipboard-text="https://2023-comp0016-avanade-team4.github.io/diagnoseai-dev-blog/posts/week-02/#task-breakdown" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Task breakdown" href="#task-breakdown">
&lt;svg class="gblog-icon gblog_link">&lt;use xlink:href="#gblog_link">&lt;/use>&lt;/svg>
&lt;/a>
&lt;/div>
&lt;p>Tasks for developing the three main aspects of the project i.e. Uploader, Web and , Core were identified. These tasks were added to the Kanban project board with the appropriate links.&lt;/p>
&lt;p>The Kanban board can be found &lt;a
class="gblog-markdown__link"
href="https://github.com/orgs/2023-comp0016-avanade-team4/projects/2"
>here&lt;/a>. Here is a screenshot of the todo section: &lt;p class="md__image">
&lt;img src="/diagnoseai-dev-blog/images/kanban-todo.png" alt="Image of todo section of the kanban" />
&lt;/p>
&lt;/p></content></entry><entry><title>Week 1 - Architecture Design</title><link href="https://2023-comp0016-avanade-team4.github.io/diagnoseai-dev-blog/posts/week-01/" rel="alternate" type="text/html" hreflang="en"/><id>https://2023-comp0016-avanade-team4.github.io/diagnoseai-dev-blog/posts/week-01/</id><published>2023-11-13T23:38:32+00:00</published><updated>2023-11-13T23:38:32+00:00</updated><content type="html">
&lt;p>This week (Monday was 13 November 2023) was reading week, which
consisted of the deadline for our Human Centered Interface (HCI)
design slides.&lt;/p>
&lt;div class="flex align-center gblog-post__anchorwrap">
&lt;h1 id="hci-deliverable"
>
HCI Deliverable
&lt;/h1>
&lt;a data-clipboard-text="https://2023-comp0016-avanade-team4.github.io/diagnoseai-dev-blog/posts/week-01/#hci-deliverable" class="gblog-post__anchor clip flex align-center" aria-label="Anchor HCI Deliverable" href="#hci-deliverable">
&lt;svg class="gblog-icon gblog_link">&lt;use xlink:href="#gblog_link">&lt;/use>&lt;/svg>
&lt;/a>
&lt;/div>
&lt;p>After iterating our sketches and prototype with our client, they were
fairly happy with the final interactive prototype, which we
incorporated into our slides.&lt;/p>
&lt;p>The aforementioned slides can be found via &lt;a
class="gblog-markdown__link"
href="/diagnoseai-dev-blog/Report.pdf"
>this link&lt;/a>. Here is
a small screenshot of it:&lt;/p>
&lt;p>&lt;p class="md__image">
&lt;img src="/diagnoseai-dev-blog/images/2023-11-27_23-51.png" alt="image of first slide of diagnoseai" />
&lt;/p>
&lt;/p>
&lt;div class="flex align-center gblog-post__anchorwrap">
&lt;h1 id="proof-of-concept-code"
>
Proof of Concept code
&lt;/h1>
&lt;a data-clipboard-text="https://2023-comp0016-avanade-team4.github.io/diagnoseai-dev-blog/posts/week-01/#proof-of-concept-code" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Proof of Concept code" href="#proof-of-concept-code">
&lt;svg class="gblog-icon gblog_link">&lt;use xlink:href="#gblog_link">&lt;/use>&lt;/svg>
&lt;/a>
&lt;/div>
&lt;p>To demonstrate the feasibility of this project, we whipped up a script
that does the following things:&lt;/p>
&lt;ol>
&lt;li>Gets triggered by an upload to a Blob storage, via Azure Function Apps.&lt;/li>
&lt;li>Parses a document, and extracts the text (using &lt;a
class="gblog-markdown__link"
href="https://azure.microsoft.com/en-gb/products/ai-services/ai-document-intelligence"
>Document Intelligence&lt;/a>);&lt;/li>
&lt;li>Sends the text to a text embedding model, such as
&lt;code>text-embedding-ada-002&lt;/code> to get embeddings;&lt;/li>
&lt;li>Store the embeddings into a vector store, such as &lt;a
class="gblog-markdown__link"
href="https://azure.microsoft.com/en-gb/products/ai-services/ai-search"
>Azure AI Search&lt;/a>.&lt;/li>
&lt;/ol>
&lt;p>Then, we configured Azure AI Search as a data source to an Azure
OpenAI deployment, which, for the purposes of demonstration, was
&lt;code>gpt-35-turbo&lt;/code>.&lt;/p>
&lt;p>The results were as expected; the model was able to support its
answers with phrases quoted from the text, and even provided
references based on the uploaded documents:&lt;/p>
&lt;p>&lt;p class="md__image">
&lt;img src="/diagnoseai-dev-blog/images/demo-poc-1.jpg" alt="image of demo response" />
&lt;/p>
&lt;/p>
&lt;p>The code for this is available in &lt;a
class="gblog-markdown__link"
href="https://github.com/2023-comp0016-avanade-team4/diagnoseai-core/blob/7910e761ddbae4e76b7115ed9ce519730f93787a/function_app.py"
>commit 7910e76 (requires
authorization)&lt;/a>.&lt;/p>
&lt;div class="flex align-center gblog-post__anchorwrap">
&lt;h1 id="github"
>
GitHub
&lt;/h1>
&lt;a data-clipboard-text="https://2023-comp0016-avanade-team4.github.io/diagnoseai-dev-blog/posts/week-01/#github" class="gblog-post__anchor clip flex align-center" aria-label="Anchor GitHub" href="#github">
&lt;svg class="gblog-icon gblog_link">&lt;use xlink:href="#gblog_link">&lt;/use>&lt;/svg>
&lt;/a>
&lt;/div>
&lt;p>We set up a GitHub organisation account containing our code (and this
blog), and shared it with our IXN mentor.&lt;/p>
&lt;p>The GitHub organisation can be found via &lt;a
class="gblog-markdown__link"
href="https://github.com/orgs/2023-comp0016-avanade-team4"
>this
link&lt;/a>.&lt;/p>
&lt;p>We also share a Kanban board, which can be found
&lt;a
class="gblog-markdown__link"
href="https://github.com/orgs/2023-comp0016-avanade-team4/projects/2"
>here&lt;/a>.&lt;/p>
&lt;div class="flex align-center gblog-post__anchorwrap">
&lt;h1 id="next-week"
>
Next week
&lt;/h1>
&lt;a data-clipboard-text="https://2023-comp0016-avanade-team4.github.io/diagnoseai-dev-blog/posts/week-01/#next-week" class="gblog-post__anchor clip flex align-center" aria-label="Anchor Next week" href="#next-week">
&lt;svg class="gblog-icon gblog_link">&lt;use xlink:href="#gblog_link">&lt;/use>&lt;/svg>
&lt;/a>
&lt;/div>
&lt;p>We decided to start drawing up some requirements, and create an
overall systems architecture diagram to better communicate what we
want to achieve by the end of the project.&lt;/p></content></entry></feed>